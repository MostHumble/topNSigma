{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MostHumble/topNSigma/blob/main/TopNSigma_Sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LogitsProcessor, LogitsProcessorList\n",
        "from transformers.utils.doc import add_start_docstrings\n",
        "from transformers.generation.logits_process import TemperatureLogitsWarper\n",
        "\n",
        "class TopNSigmaLogitsWarper(LogitsProcessor):\n",
        "    \"\"\"\n",
        "    [`LogitsProcessor`] that performs Top-nσ sampling. This method filters the logits based on their deviation\n",
        "    from the maximum logit value.\n",
        "\n",
        "    The filtering rule is to keep all tokens where the logit `l_i` satisfies `l_i > M - n * σ`, where `M` is the\n",
        "    maximum logit, `σ` is the standard deviation of the logits, and `n` is a configurable multiplier. Logits\n",
        "    that do not meet this condition are set to a filter value (typically -inf).\n",
        "\n",
        "    This approach adapts the filtering based on the distribution of the logits. A flatter distribution (higher\n",
        "    standard deviation) will result in a more aggressive filtering, while a spikier distribution (lower\n",
        "    standard deviation) will be more permissive.\n",
        "\n",
        "    Args:\n",
        "        n (`float`):\n",
        "            The multiplier for the standard deviation. This value controls the aggressiveness of the filtering.\n",
        "            Higher values of `n` lead to more aggressive filtering (keeping fewer tokens). A typical range for\n",
        "            `n` might be between 2 and 6.\n",
        "        filter_value (`float`, *optional*, defaults to -inf):\n",
        "            All filtered values will be set to this float value.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n: float, filter_value: float = -float(\"Inf\")):\n",
        "        if not isinstance(n, float) or n < 0:\n",
        "            raise ValueError(f\"`n` has to be a non-negative float, but is {n}\")\n",
        "\n",
        "        self.n = n\n",
        "        self.filter_value = filter_value\n",
        "\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        # Calculate M (max logit) and sigma (standard deviation of logits) for each sequence in the batch\n",
        "        max_logit, _ = torch.max(scores, dim=-1, keepdim=True)\n",
        "        std_logit = torch.std(scores, dim=-1, keepdim=True)\n",
        "\n",
        "        # Calculate the filtering threshold for each sequence\n",
        "        threshold = max_logit - self.n * std_logit\n",
        "\n",
        "        # Create a boolean mask for tokens to be removed\n",
        "        tokens_to_remove = scores < threshold\n",
        "\n",
        "        # Apply the filter\n",
        "        scores_processed = scores.masked_fill(tokens_to_remove, self.filter_value)\n",
        "        return scores_processed\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example Usage\n",
        "    from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
        "\n",
        "    # Set a seed for reproducibility\n",
        "    set_seed(42)\n",
        "\n",
        "    checkpoint = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
        "\n",
        "    device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "    model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n",
        "\n",
        "    # Input text\n",
        "    messages = [{\"role\": \"user\", \"content\": \"Can you explain the concept of gravity?\"}]\n",
        "    input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    print(\"--- Standard Sampling (for comparison) ---\")\n",
        "    # With standard sampling, the output can be quite random.\n",
        "    outputs_standard = model.generate(\n",
        "        inputs,\n",
        "        do_sample=True,\n",
        "        max_length=100,\n",
        "        top_k=0 # Deactivate top-k to see the full effect of sampling\n",
        "    )\n",
        "    print(tokenizer.batch_decode(outputs_standard, skip_special_tokens=True)[0])\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n",
        "    print(\"--- TopNSigma Sampling (n=1.5) without Temperature ---\")\n",
        "    # With TopNSigma sampling, the output is constrained to more likely tokens.\n",
        "    top_n_sigma_warper = TopNSigmaLogitsWarper(n=1.5)\n",
        "    outputs_top_n_sigma = model.generate(\n",
        "        inputs,\n",
        "        do_sample=True,\n",
        "        max_length=100,\n",
        "        logits_processor=LogitsProcessorList([top_n_sigma_warper])\n",
        "    )\n",
        "    print(tokenizer.batch_decode(outputs_top_n_sigma, skip_special_tokens=True)[0])\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    print(\"--- TopNSigma Sampling (n=0.5) with Temperature (T=0.7) ---\")\n",
        "    # Here we combine both processors. The order matters: typically filtering processors\n",
        "    # like TopNSigma go before temperature scaling.\n",
        "    temp_warper = TemperatureLogitsWarper(temperature=0.7)\n",
        "    top_n_sigma_warper_combined = TopNSigmaLogitsWarper(n=0.5)\n",
        "\n",
        "    outputs_combined = model.generate(\n",
        "        inputs,\n",
        "        do_sample=True,\n",
        "        max_length=100,\n",
        "        logits_processor=LogitsProcessorList([top_n_sigma_warper_combined, temp_warper])\n",
        "    )\n",
        "    print(tokenizer.batch_decode(outputs_combined, skip_special_tokens=True)[0])\n",
        "    print(\"-\" * 50)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Standard Sampling (for comparison) ---\n",
            "system\n",
            "You are a helpful AI assistant named SmolLM, trained by Hugging Face\n",
            "user\n",
            "Can you explain the concept of gravity?\n",
            "assistant\n",
            "Certainly! Gravity is a fundamental force of nature that keeps objects in alignment with each other and objects in the universe. It is widely expressed within various forms of science and engineering, interactive simulations, documents, software, and educational materials. Practitioners of gravitational manipulation use this energy to power gravitational principles to achieve various unexpected outcomes\n",
            "--------------------------------------------------\n",
            "--- TopNSigma Sampling (n=1.5) without Temperature ---\n",
            "system\n",
            "You are a helpful AI assistant named SmolLM, trained by Hugging Face\n",
            "user\n",
            "Can you explain the concept of gravity?\n",
            "assistant\n",
            "Sure, as a Hugging Face AI, I've been trained on many topics and can certainly summarize the concept of gravity.\n",
            "\n",
            "Gravity, also known as 'g', is a fundamental force of nature that describes the attractive force between any two objects with mass. It's the reason why objects fall towards\n",
            "--------------------------------------------------\n",
            "--- TopNSigma Sampling (n=0.5) with Temperature (T=0.7) ---\n",
            "system\n",
            "You are a helpful AI assistant named SmolLM, trained by Hugging Face\n",
            "user\n",
            "Can you explain the concept of gravity?\n",
            "assistant\n",
            "Absolutely, gravity is a fundamental force of nature that acts between objects with mass or energy. According to Einstein's theory of general relativity, gravity is not a force that acts between objects, but rather the result of the geometry of spacetime.\n",
            "\n",
            "Imagine spacetime as a fabric that combines space and time. Any\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYqqUD_Sougf",
        "outputId": "8e907899-0251-42c7-aeae-fd3299442f1d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0KwEvSOVzYTO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}